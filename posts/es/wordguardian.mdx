---
title: "El proyecto WordGuardian"
date: "2025-06-02"
summary: "Durante el Ãºltimo mes me he sumergido en un proyecto personal que querÃ­a ser juego, experimento, y quizÃ¡ un poco protesta: **WordGuardian**. Una web para jugar con definiciones absurdas, reales e inventadas. Pero tambiÃ©n una ventana a la riqueza semÃ¡ntica de Wikidata y un baÃ±o de agua frÃ­a sobre la realidad de crear una web indie en 2025."
image: "/images/wordguradian-post.png" 
categories: ["general", "tecnologÃ­a", "juego", "lenguaje", "wikidata", "astro", "webindie"]
slug: "wordguardian"
---

# El proyecto  
**VersiÃ³n 1.0**  
âœï¸ Asistido con IA: Este artÃ­culo ha sido redactado con la ayuda de ChatGPT (OpenAI), a partir de bocetos e ideas originales de **Francesc LÃ³pez MariÃ³**.

Durante el Ãºltimo mes me he sumergido en un proyecto personal que querÃ­a ser juego, experimento, y quizÃ¡ un poco protesta: **WordGuardian**.

Una web para jugar con definiciones absurdas, reales e inventadas. Pero tambiÃ©n una ventana a la riqueza semÃ¡ntica de Wikidata y un baÃ±o de agua frÃ­a sobre la realidad de crear una web indie en 2025.

## ğŸ§© Objetivo  
QuerÃ­a crear un juego en el que los usuarios adivinasen definiciones plausibles, generadas o extraÃ­das de forma automÃ¡tica.  

**Pero el camino no ha sido nada sencillo.**  
He utilizado Astro y Preact para evitar el *FOUC* y hacerlo responsive, y he trabajado con gigantescos *dumps* de Wikidata descomprimiendo con `pbzip2`, `zstd` y scripts en **Rust** paralelos.

## âš™ï¸ Stack y tÃ©cnicas  

- **Frontend**: Astro, Preact, Shoelace, Vanilla Extract  
  > *Astro ha sido una joya inesperada.* Permite combinar componentes de distintos frameworks y, sobre todo, hacer **renderizado del lado del servidor (SSR)** de forma muy eficiente. Esto facilita que los buscadores indexen el contenido sin problemas â€”una diferencia clave si quieres tener opciones reales de SEO en 2025. AdemÃ¡s, exponer una pequeÃ±a API del servidor (con endpoints tipo `/api/xyz`) es directo y sin complicaciones, sin tener que montar un backend completo.  
- **Backend**: Node.js para scrapings, scripts paralelos en Rust para parsear Wikidata  
- **Procesamiento**: *dumps* de Wikidata con p31, p279, p1629... todo un mundo  
- **NLP**: generaciÃ³n de distractores con Groq, heurÃ­sticas con *embeddings*.
- **Otros**: Carga sin *FOUC* (*Flash of Unstyled Content*), es decir, evitar que la pÃ¡gina se vea "fea" durante unas milÃ©simas de segundo antes de que se carguen los estilos. TambiÃ©n hice una optimizaciÃ³n mÃ­nima y, como siempre, muchas lÃ­neas de consola.

TambiÃ©n he utilizado el proyecto [**Wiktextract**](https://github.com/tatuylonen/wiktextract), desarrollado por **Tatu YlÃ¶nen**, y la base de datos publicada en [**Kaikki.org**](https://kaikki.org), que ofrece los contenidos de Wiktionary de forma estructurada y usable. Sin esta fuente, habrÃ­a sido mucho mÃ¡s lento construir una base lÃ©xica fiable para el juego.

## ğŸ’¡ Aprendizajes  

- **Wikidata es un tesoro**, pero navegar por ella sin mapa es una odisea: Ã­tems, propiedades, lexemas, glosas, referencias cruzadas... y consultas **SPARQL** que parecen rituales mÃ¡gicos.  
- He descubierto herramientas como:
  - [Wikidata Toolkit](https://github.com/Wikidata-Toolkit/Wikidata-Toolkit)  
  - [KGTK Search](https://github.com/usc-isi-i2/kgtk-search)  
  - [Wikibase CLI](https://github.com/maxlath/wikibase-cli/tree/main)  
  - [wikidata-filter](https://github.com/alexkreidler/wikidata-filter)  
  - [SPARQL](https://en.wikipedia.org/wiki/SPARQL)
- Los *dumps* de Wikidata suelen venir en **formato JSONL** (JSON Lines): un fichero donde cada lÃ­nea es un objeto JSON independiente. Es perfecto para procesamiento en *streaming*, porque no hace falta cargarlo todo en memoria. Pero cuando tienes 90 GB... cualquier estrategia requiere paciencia, mucha.
- **Diferencias de compresiÃ³n**:  
  - `bz2` es muy comÃºn en los *dumps* oficiales, pero *lentÃ­simo* de descomprimir.  
  - `zstd`, en cambio, es **mucho mÃ¡s rÃ¡pido**, especialmente con mÃºltiples hilos. Con `pzstd -d -p10` puedes acelerar bastante la carga, aunque despuÃ©s el cuello de botella es tu propio cÃ³digo ğŸ˜…
- Generar distractores plausibles no es trivial. Hacerlo con Groq ha sido divertido, pero no siempre fiable.  
- Generar definiciones falsas pero creÃ­bles no es nada fÃ¡cil. Con Groq o HuggingFace, afinando los *prompts*, pero hay que hilar muy fino.  
- **Los dumps no son para dÃ©biles.** Y menos si pesan 90 GB.
- TambiÃ©n aprendÃ­ a encapsular pequeÃ±os servicios NLP con Docker, exponiendo APIs locales de forma sencilla. Con una imagen ligera basada en `python:3.11-slim` y un `requirements.txt`, pude desplegar rÃ¡pidamente un servicio para hacer cÃ¡lculos semÃ¡nticos o similitudes entre frases. Ideal para hacer pruebas locales sin lÃ­os de dependencias.
- TambiÃ©n estuve explorando el proyecto [**Common Crawl**](https://commoncrawl.org/) para extraer URLs de la web pÃºblica. Aunque finalmente no lo integrÃ©, preparÃ© un script para filtrar los enlaces y construir un corpus propio. La idea era utilizarlo para generar preguntas o validar definiciones con contenido real, pero quedÃ³ en *stand-by*... por ahora.

## ğŸ“‰ Â¿MonetizaciÃ³n? Ay...

TenÃ­a la ilusiÃ³n de cubrir aunque fuera el *hosting* con anuncios. Pero los datos son claros:

- 462 visitas
- 22 usuarios activos
- 0,00â€¯â‚¬ de ingresos
- Una media de 7 minutos por usuario... pero nadie clica

> En 2025, si no tienes TikTok, una newsletter o 1 millÃ³n de pÃ¡ginas vistas, la publicidad no paga ni el cafÃ©.  
> Hacer una web no es suficiente. Tienes que ser *showman*, tener dinero, o hacer *marketing* diario.

## ğŸ¯ Â¿Y ahora quÃ©?

No lo voy a matar.  
**WordGuardian seguirÃ¡ vivo** como proyecto experimental y como pequeÃ±o homenaje a las palabras y a Wikidata.  

QuizÃ¡ evolucione hacia una app educativa. QuizÃ¡ sea la base de un juego nuevo.  
O quizÃ¡ quede como monumento al tiempo invertido en una idea que aÃºn me hace sonreÃ­r.

TambiÃ©n me ronda por la cabeza empezar a **investigar cÃ³mo usar la ontologÃ­a de Wikidata para generar preguntas alineadas con campos de conocimiento**: ciencia, historia, cultura popular, etc.  
Aprovechar la jerarquÃ­a de subclases (`p279`) e instancias (`p31`) para construir *niveles temÃ¡ticos* o *quizzes por Ã¡mbitos*, y hacer que el juego sea un poco menos "psicodÃ©lico" y un poco mÃ¡s navegable.  

ğŸ‘‰ PruÃ©balo: [https://eurekatop.com/wordguardian](https://eurekatop.com/wordguardian)  
ğŸ“– CÃ³digo abierto (pronto en GitHub)  

Un proyecto de [**mutiitu.com**](https://www.mutiitu.com)

Â© Francesc LÃ³pez MariÃ³, 2025
