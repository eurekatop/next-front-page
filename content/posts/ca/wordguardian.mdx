---
title: "El projecte WordGuardian"
date: "2025-06-02"
summary: "Durant el darrer mes mâ€™he submergit en un projecte personal que volia ser joc, experiment, i potser una mica protesta: **WordGuardian**. Una web per jugar amb definicions absurdes, reals i inventades. PerÃ² tambÃ© una finestra a la riquesa semÃ ntica de Wikidata i un bany dâ€™aigua freda sobre la realitat de crear una web indie el 2025."
image: "/images/wordguradian-post.png" 
categories: ["general","tecnologia", "joc", "llenguatge", "wikidata", "astro", "webindie"]
slug: "wordguardian"
---

# El projecte   
**VersiÃ³ 1.0**  
âœï¸ Assistit amb AI: Aquest article ha estat redactat amb lâ€™ajuda de ChatGPT (OpenAI), a partir dâ€™esbossos i idees originals de **Francesc LÃ³pez MariÃ³**.

Durant el darrer mes mâ€™he submergit en un projecte personal que volia ser joc, experiment, i potser una mica protesta: **WordGuardian**.

Una web per jugar amb definicions absurdes, reals i inventades. PerÃ² tambÃ© una finestra a la riquesa semÃ ntica de Wikidata i un bany dâ€™aigua freda sobre la realitat de crear una web indie el 2025.

## ğŸ§© Objectiu  
Volia fer un joc on els usuaris endevinessin definicions plausibles, generades o extretes de forma automÃ tica.  

**PerÃ² el camÃ­ no ha estat gens simple.**  
He usat Astro i Preact per evitar el FUOC i fer-ho responsive, i he treballat amb dumps gegants de Wikidata descomprimint amb `pbzip2`, `zstd` i scripts en **Rust** paralÂ·lels.

## âš™ï¸ Stack i tÃ¨cniques  

- **Frontend**: Astro, Preact, Shoelace, Vanilla Extract  
  > *Astro ha estat una joia inesperada.* Permet combinar components amb diferents frameworks i, sobretot, fer **renderitzat del costat del servidor (SSR)** molt eficient. AixÃ² facilita que els cercadors indexin el contingut sense problemes â€”una diferÃ¨ncia clau si vols tenir opcions reals a SEO el 2025. A mÃ©s, exposar una petita API del servidor (amb endpoints tipus `/api/xyz`) Ã©s directe i sense complicacions, sense haver de muntar un backend sencer.  
- **Backend**: Node.js per scrapings, scripts paralÂ·lels en Rust per parsejar Wikidata  
- **Processament**: dumps de Wikidata amb p31, p279, p1629... tot un mÃ³n  
- **NLP**: generaciÃ³ de distractors amb Groq, heurÃ­stiques amb embeddings.
- **Altres**: CÃ rrega sense *FOUC* (*Flash of Unstyled Content*), Ã©s a dir, evitar que la pÃ gina es vegi "lletja" durant unes milÂ·lÃ¨simes de segon abans que es carreguin els estils. TambÃ© he fet una optimitzaciÃ³ mÃ­nima i, com sempre, moltes lÃ­nies de consola.

TambÃ© he utilitzat el projecte [**Wiktextract**](https://github.com/tatuylonen/wiktextract), desenvolupat per **Tatu YlÃ¶nen**, i la base de dades publicada a [**Kaikki.org**](https://kaikki.org), que ofereix els continguts de Wiktionary de forma estructurada i usable. Sense aquesta font, hauria estat molt mÃ©s lent construir una base lÃ¨xica fiable per al joc.

## ğŸ’¡ Aprenentatges  

- **Wikidata Ã©s un tresor**, perÃ² navegar-hi sense mapa Ã©s una odissea: items, propietats, lexemes, glosses, referÃ¨ncies creuades... i consultes **SPARQL** que semblen rituals mÃ gics.  
- He descobert eines com:
  - [Wikidata Toolkit](https://github.com/Wikidata-Toolkit/Wikidata-Toolkit)  
  - [KGTK Search](https://github.com/usc-isi-i2/kgtk-search)  
  - [Wikibase CLI](https://github.com/maxlath/wikibase-cli/tree/main)  
  - [wikidata-filter](https://github.com/alexkreidler/wikidata-filter)  
  - [SPARQL](https://en.wikipedia.org/wiki/SPARQL)
- Els dumps de Wikidata venen sovint en **format JSONL** (JSON Lines): un fitxer on cada lÃ­nia Ã©s un objecte JSON independent. Ã‰s perfecte per processament en streaming, perquÃ¨ no cal carregar-ho tot a memÃ²ria. PerÃ² quan tens 90 GB... qualsevol estratÃ¨gia requereix paciÃ¨ncia, molta.
- **DiferÃ¨ncia de compressiÃ³**:  
  - `bz2` Ã©s molt comÃº en els dumps oficials, perÃ² *lentÃ­ssim* de descomprimir.  
  - `zstd`, en canvi, Ã©s **molt mÃ©s rÃ pid**, especialment amb mÃºltiples fils. Amb `pzstd -d -p10` pots accelerar bastant la cÃ rrega, encara que desprÃ©s el coll dâ€™ampolla Ã©s el teu codi ğŸ˜…
- Generar distractors plausibles no Ã©s trivial. Fer-ho amb Groq ha estat divertit, perÃ² no sempre fiable.  
- Generar definicions falses perÃ² creÃ¯bles no Ã©s trivial. Amb Groq o HuggingFace, millorant amb prompts, perÃ² cal filar prim.  
- **Els dumps no sÃ³n per dÃ¨bils.** I menys si pesen 90 GB.
- TambÃ© he aprÃ¨s a encapsular petits serveis NLP amb Docker, exposant APIs locals de forma senzilla. Amb una imatge lleugera basada en `python:3.11-slim` i un `requirements.txt`, vaig poder desplegar rÃ pidament un servei per fer cÃ lculs semÃ ntics o similituds entre frases. Ideal per fer proves locals sense embolics de dependÃ¨ncies.
- TambÃ© vaig estar explorant el projecte [**Common Crawl**](https://commoncrawl.org/) per extreure URLs de la web pÃºblica. Tot i que finalment no ho vaig integrar, vaig preparar un script per filtrar els enllaÃ§os  i construir un corpus propi. La idea era utilitzar-lo per generar preguntes o validar definicions amb contingut real, perÃ² va quedar en stand-by... per ara.


## ğŸ“‰ MonetitzaciÃ³? Ai...

Tenia la ilÂ·lusiÃ³ de cobrir ni que fos el hosting amb anuncis. PerÃ² les dades sÃ³n clares:

- 462 visites
- 22 usuaris actius
- 0,00â€¯â‚¬ dâ€™ingressos
- Una mitjana de 7 minuts per usuari... perÃ² ningÃº clica

> Al 2025, si no tens TikTok, una newsletter o 1 miliÃ³ de pÃ gines vistes, la publicitat no paga ni el cafÃ¨.  
> Fer una web no nâ€™Ã©s prou. Has de ser showman, tenir diners, o fer mÃ rqueting diari.

## ğŸ¯ I ara quÃ¨?

No el matarÃ©.  
**WordGuardian seguirÃ  viu** com a projecte experimental i com a petit homenatge a les paraules i a Wikidata.  

Potser evolucionarÃ  cap a una app educativa. Potser serÃ  la base dâ€™un joc nou.  
O potser quedarÃ  com a monument al temps invertit en una idea que encara em fa somriure.

TambÃ© em ronda pel cap comenÃ§ar a **investigar com fer servir lâ€™ontologia de Wikidata per generar preguntes alineades amb camps de coneixement**: ciÃ¨ncia, histÃ²ria, cultura popular, etc.  
Aprofitar la jerarquia de subclasses (`p279`) i instÃ ncies (`p31`) per construir *nivells temÃ tics* o *quizzes per Ã mbits*, i fer que el joc sigui una mica menys "psicodÃ¨lic" i una mica mÃ©s navegable.  



ğŸ‘‰ Provaâ€™l: [https://eurekatop.com/wordguardian](https://eurekatop.com/wordguardian)  
ğŸ“– Codi obert (aviat a GitHub)  

Un projecte de [**mutiitu.com**](https://www.mutiitu.com)

Â© Francesc LÃ³pez MariÃ³, 2025
